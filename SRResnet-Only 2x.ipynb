{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:12.218011200Z",
     "start_time": "2023-07-25T06:36:09.838028100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:12.233562Z",
     "start_time": "2023-07-25T06:36:12.222012Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, kernelSize = 3, inChannels = 128, outChannels = 128, strd = 1, paddng = 1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = inChannels, out_channels = outChannels, kernel_size = kernelSize, stride = strd, padding = paddng),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = inChannels, out_channels = outChannels, kernel_size = kernelSize, stride = strd, padding = paddng),\n",
    "            nn.BatchNorm2d(128)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return torch.add(out, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:12.275873500Z",
     "start_time": "2023-07-25T06:36:12.234577200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, inChannels,scaleFactor):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels= inChannels, out_channels= inChannels * scaleFactor ** 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.ps = nn.PixelShuffle(scaleFactor)\n",
    "        self.act = nn.PReLU(inChannels)\n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:12.276872800Z",
     "start_time": "2023-07-25T06:36:12.255708200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SRResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRResnet, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Conv2d(kernel_size=9, stride=1, in_channels=3, out_channels=128, padding=4)\n",
    "        self.l2 = nn.PReLU()\n",
    "\n",
    "        self.residuals = nn.Sequential()\n",
    "        for _ in range(0, 8):\n",
    "            self.residuals.add_module('residualBlock',ResidualBlock())\n",
    "\n",
    "        self.postResiduals = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 128, out_channels=128, kernel_size= 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "        )\n",
    "        self.upsample = UpsampleBlock(128, 2)\n",
    "        #self.upsample2 = UpsampleBlock(128, 2)\n",
    "\n",
    "        self.final = nn.Conv2d(128, 3, kernel_size= 9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x1 = self.l2(x)\n",
    "        x = self.residuals(x1)\n",
    "        x = self.postResiduals(x)\n",
    "        x = torch.add(x, x1)\n",
    "        x = self.upsample(x)\n",
    "        #x = self.upsample2(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:13.616896Z",
     "start_time": "2023-07-25T06:36:12.272344100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set the path to your data folder\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "\n",
    "# Define the transformations for your data\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),  # Resize the images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image pixels to the range [-1, 1]\n",
    "])\n",
    "transformLr = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),\n",
    "    transforms.Resize((128,128)), # Resize the images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image pixels to the range [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Load the high-resolution and low-resolution images\n",
    "hr_dataset = ImageFolder(root=data_path + \"lr\", transform=transform)\n",
    "lr_dataset = ImageFolder(root=data_path + \"lr\", transform=transformLr)\n",
    "#sr_dataset = ImageFolder(root=data_path + \"autoencodertrain\", transform=transform)\n",
    "\n",
    "# Create the data loader for high-resolution and low-resolution images\n",
    "batch_size = 15\n",
    "num_workers = 2  # Set the number of worker processes for data loading\n",
    "hr_data_loader = DataLoader(hr_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "lr_data_loader = DataLoader(lr_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:36:13.774453700Z",
     "start_time": "2023-07-25T06:36:13.616896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# Carrega Rede\n",
    "srresnet = SRResnet()\n",
    "#srresnet.load_state_dict(torch.load('Model_Snapshots/Gen/Modelo_atual.pt'))\n",
    "\n",
    "# Move the models to the device\n",
    "srresnet.to(device)\n",
    "\n",
    "content_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-25T06:37:07.025442500Z",
     "start_time": "2023-07-25T06:36:13.774453700Z"
    },
    "collapsed": false
   },
   "source": [
    "test_path = \"Testes/\"\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "test_dataset = ImageFolder(root=test_path, transform= test_transform)\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "test_data_loader = DataLoader(test_dataset, batch_size= batch_size, num_workers= num_workers)\n",
    "\n",
    "i = 1\n",
    "for image in test_data_loader:\n",
    "    sr_images = srresnet(image[0].float().to(device))\n",
    "    save_image(sr_images, f\"{i}.png\", normalize = True)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "num_epochs = 150\n",
    "save_interval = 50\n",
    "arrayError = np.zeros(shape=save_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T19:30:12.013571Z",
     "start_time": "2023-07-16T19:29:22.804350800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/150], Step [1/7886], Mean Loss: 0.007666.\n",
      "Saved SRResNet model and images at epoch 1, batch 50.\n",
      "Epoch [1/150], Step [51/7886], Mean Loss: 6.390251.\n",
      "Saved SRResNet model and images at epoch 1, batch 100.\n",
      "Epoch [1/150], Step [101/7886], Mean Loss: 28.019765.\n",
      "Saved SRResNet model and images at epoch 1, batch 150.\n",
      "Epoch [1/150], Step [151/7886], Mean Loss: 0.830430.\n",
      "Saved SRResNet model and images at epoch 1, batch 200.\n",
      "Epoch [1/150], Step [201/7886], Mean Loss: 11.285176.\n",
      "Saved SRResNet model and images at epoch 1, batch 250.\n",
      "Epoch [1/150], Step [251/7886], Mean Loss: 10.461325.\n",
      "Saved SRResNet model and images at epoch 1, batch 300.\n",
      "Epoch [1/150], Step [301/7886], Mean Loss: 0.993787.\n",
      "Saved SRResNet model and images at epoch 1, batch 350.\n",
      "Epoch [1/150], Step [351/7886], Mean Loss: 2.169505.\n",
      "Saved SRResNet model and images at epoch 1, batch 400.\n",
      "Epoch [1/150], Step [401/7886], Mean Loss: 7.735205.\n",
      "Saved SRResNet model and images at epoch 1, batch 450.\n",
      "Epoch [1/150], Step [451/7886], Mean Loss: 0.349844.\n",
      "Saved SRResNet model and images at epoch 1, batch 500.\n",
      "Epoch [1/150], Step [501/7886], Mean Loss: 3.974756.\n",
      "Saved SRResNet model and images at epoch 1, batch 550.\n",
      "Epoch [1/150], Step [551/7886], Mean Loss: 3.411411.\n",
      "Saved SRResNet model and images at epoch 1, batch 600.\n",
      "Epoch [1/150], Step [601/7886], Mean Loss: 0.621272.\n",
      "Saved SRResNet model and images at epoch 1, batch 650.\n",
      "Epoch [1/150], Step [651/7886], Mean Loss: 1.552567.\n",
      "Saved SRResNet model and images at epoch 1, batch 700.\n",
      "Epoch [1/150], Step [701/7886], Mean Loss: 0.414608.\n",
      "Saved SRResNet model and images at epoch 1, batch 750.\n",
      "Epoch [1/150], Step [751/7886], Mean Loss: 0.652118.\n",
      "Saved SRResNet model and images at epoch 1, batch 800.\n",
      "Epoch [1/150], Step [801/7886], Mean Loss: 2.068928.\n",
      "Saved SRResNet model and images at epoch 1, batch 850.\n",
      "Epoch [1/150], Step [851/7886], Mean Loss: 0.218702.\n",
      "Saved SRResNet model and images at epoch 1, batch 900.\n",
      "Epoch [1/150], Step [901/7886], Mean Loss: 0.347882.\n",
      "Saved SRResNet model and images at epoch 1, batch 950.\n",
      "Epoch [1/150], Step [951/7886], Mean Loss: 0.989025.\n",
      "Saved SRResNet model and images at epoch 1, batch 1000.\n",
      "Epoch [1/150], Step [1001/7886], Mean Loss: 0.506524.\n",
      "Saved SRResNet model and images at epoch 1, batch 1050.\n",
      "Epoch [1/150], Step [1051/7886], Mean Loss: 0.204453.\n",
      "Saved SRResNet model and images at epoch 1, batch 1100.\n",
      "Epoch [1/150], Step [1101/7886], Mean Loss: 0.132102.\n",
      "Saved SRResNet model and images at epoch 1, batch 1150.\n",
      "Epoch [1/150], Step [1151/7886], Mean Loss: 1.730274.\n",
      "Saved SRResNet model and images at epoch 1, batch 1200.\n",
      "Epoch [1/150], Step [1201/7886], Mean Loss: 0.056735.\n",
      "Saved SRResNet model and images at epoch 1, batch 1250.\n",
      "Epoch [1/150], Step [1251/7886], Mean Loss: 0.336799.\n",
      "Saved SRResNet model and images at epoch 1, batch 1300.\n",
      "Epoch [1/150], Step [1301/7886], Mean Loss: 0.148796.\n",
      "Saved SRResNet model and images at epoch 1, batch 1350.\n",
      "Epoch [1/150], Step [1351/7886], Mean Loss: 0.116097.\n",
      "Saved SRResNet model and images at epoch 1, batch 1400.\n",
      "Epoch [1/150], Step [1401/7886], Mean Loss: 0.234104.\n",
      "Saved SRResNet model and images at epoch 1, batch 1450.\n",
      "Epoch [1/150], Step [1451/7886], Mean Loss: 0.142596.\n",
      "Saved SRResNet model and images at epoch 1, batch 1500.\n",
      "Epoch [1/150], Step [1501/7886], Mean Loss: 0.148119.\n",
      "Saved SRResNet model and images at epoch 1, batch 1550.\n",
      "Epoch [1/150], Step [1551/7886], Mean Loss: 0.131698.\n",
      "Saved SRResNet model and images at epoch 1, batch 1600.\n",
      "Epoch [1/150], Step [1601/7886], Mean Loss: 0.077294.\n",
      "Saved SRResNet model and images at epoch 1, batch 1650.\n",
      "Epoch [1/150], Step [1651/7886], Mean Loss: 0.094797.\n",
      "Saved SRResNet model and images at epoch 1, batch 1700.\n",
      "Epoch [1/150], Step [1701/7886], Mean Loss: 0.105868.\n",
      "Saved SRResNet model and images at epoch 1, batch 1750.\n",
      "Epoch [1/150], Step [1751/7886], Mean Loss: 0.167390.\n",
      "Saved SRResNet model and images at epoch 1, batch 1800.\n",
      "Epoch [1/150], Step [1801/7886], Mean Loss: 0.135351.\n",
      "Saved SRResNet model and images at epoch 1, batch 1850.\n",
      "Epoch [1/150], Step [1851/7886], Mean Loss: 0.069615.\n",
      "Saved SRResNet model and images at epoch 1, batch 1900.\n",
      "Epoch [1/150], Step [1901/7886], Mean Loss: 0.133328.\n",
      "Saved SRResNet model and images at epoch 1, batch 1950.\n",
      "Epoch [1/150], Step [1951/7886], Mean Loss: 0.034928.\n",
      "Saved SRResNet model and images at epoch 1, batch 2000.\n",
      "Epoch [1/150], Step [2001/7886], Mean Loss: 0.145713.\n",
      "Saved SRResNet model and images at epoch 1, batch 2050.\n",
      "Epoch [1/150], Step [2051/7886], Mean Loss: 0.034113.\n",
      "Saved SRResNet model and images at epoch 1, batch 2100.\n",
      "Epoch [1/150], Step [2101/7886], Mean Loss: 0.373026.\n",
      "Saved SRResNet model and images at epoch 1, batch 2150.\n",
      "Epoch [1/150], Step [2151/7886], Mean Loss: 0.043107.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     20\u001b[0m optimizer_gen\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 22\u001b[0m \u001b[43marrayError\u001b[49m[i \u001b[38;5;241m%\u001b[39m save_interval] \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Print progress\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#if(i + 1) % 10 == 0:\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;66;03m#print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(hr_data_loader)}],\" f\"Generator Loss: {loss.item():.4f}. \")\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Print mean\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m save_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(0, num_epochs):\n",
    "    # Define the optimizers for generator and discriminator\n",
    "    lr /= 5\n",
    "    betas = (0.5, 0.9)\n",
    "    optimizer_gen = optim.Adam(srresnet.parameters(), lr = lr, betas = betas)\n",
    "    for i, (hr_images, lr_images) in enumerate(zip(hr_data_loader, lr_data_loader)):\n",
    "        #factor -= step\n",
    "        # Move images to the device\n",
    "        hr_images = hr_images[0].to(device).float()\n",
    "        lr_images = lr_images[0].to(device).float()\n",
    "\n",
    "        srresnet.zero_grad()\n",
    "        optimizer_gen.zero_grad()\n",
    "\n",
    "        # Calculating error\n",
    "        sr_images = srresnet(lr_images)\n",
    "        loss = content_loss(sr_images, hr_images)\n",
    "        loss.backward()\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        arrayError[i % save_interval] = loss.item()\n",
    "\n",
    "        # Print progress\n",
    "        #if(i + 1) % 10 == 0:\n",
    "            #print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(hr_data_loader)}],\" f\"Generator Loss: {loss.item():.4f}. \")\n",
    "        # Print mean\n",
    "        if i % save_interval == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(hr_data_loader)}], \" f\"Mean Loss: {arrayError.mean():.6f}.\")\n",
    "\n",
    "        if (i + 1) % save_interval == 0:\n",
    "            torch.save(srresnet.state_dict(), f\"Model_Snapshots/Gen/srresnet_model_epoch{epoch+1}_batch{i+1}.pt\")\n",
    "            print(f\"Saved SRResNet model and images at epoch {epoch+1}, batch {i+1}.\")\n",
    "\n",
    "            #save_image(sr_images, f\"AE-results/sr_image_epoch{epoch + 1}_batch{i+1}.png\", normalize = True)\n",
    "            save_image(sr_images, f\"Net_Results/image_epoch{epoch + 1}_batch{i+1}_sr.png\", normalize = True)\n",
    "            save_image(hr_images, f\"Net_Results/image_epoch{epoch + 1}_batch{i+1}_hr.png\", normalize = True)\n",
    "            save_image(lr_images, f\"Net_Results/image_epoch{epoch + 1}_batch{i+1}_lr.png\", normalize = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
