{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.627780800Z",
     "start_time": "2023-07-16T00:08:00.613777300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, kernelSize = 3, inChannels = 64, outChannels = 64, strd = 1, paddng = 1):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels = inChannels, out_channels = outChannels, kernel_size = kernelSize, stride = strd, padding = paddng),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.PReLU(),\n",
    "            nn.Conv2d(in_channels = inChannels, out_channels = outChannels, kernel_size = kernelSize, stride = strd, padding = paddng),\n",
    "            nn.BatchNorm2d(64)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return torch.add(out, x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.663298200Z",
     "start_time": "2023-07-16T00:08:00.631781100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "class UpsampleBlock(nn.Module):\n",
    "    def __init__(self, inChannels,scaleFactor):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels= inChannels, out_channels= inChannels * scaleFactor ** 2, kernel_size=3, stride=1, padding=1)\n",
    "        self.ps = nn.PixelShuffle(scaleFactor)\n",
    "        self.act = nn.PReLU(inChannels)\n",
    "    def forward(self, x):\n",
    "        return self.act(self.ps(self.conv(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.663298200Z",
     "start_time": "2023-07-16T00:08:00.646786700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class SRResnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRResnet, self).__init__()\n",
    "\n",
    "        self.l1 = nn.Conv2d(kernel_size=9, stride=1, in_channels=3, out_channels=64, padding=4)\n",
    "        self.l2 = nn.PReLU()\n",
    "\n",
    "        self.residuals = nn.Sequential()\n",
    "        for _ in range(0, 16):\n",
    "            self.residuals.add_module('residualBlock',ResidualBlock())\n",
    "\n",
    "        self.postResiduals = nn.Sequential(\n",
    "            nn.Conv2d(in_channels= 64, out_channels=64, kernel_size= 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "\n",
    "        self.upsample = UpsampleBlock(64, 2)\n",
    "        self.upsample2 = UpsampleBlock(64, 2)\n",
    "\n",
    "        self.final = nn.Conv2d(64, 3, kernel_size= 9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x1 = self.l2(x)\n",
    "        x = self.residuals(x1)\n",
    "        x = self.postResiduals(x)\n",
    "        x = torch.add(x, x1)\n",
    "        x = self.upsample(x)\n",
    "        x = self.upsample2(x)\n",
    "        x = self.final(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.675302200Z",
     "start_time": "2023-07-16T00:08:00.665300200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Set the path to your data folder\n",
    "\n",
    "data_path = \"dataset/\"\n",
    "\n",
    "# Define the transformations for your data\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),  # Resize the images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image pixels to the range [-1, 1]\n",
    "])\n",
    "transformLr = transforms.Compose([\n",
    "    transforms.CenterCrop((256, 256)),\n",
    "    transforms.Resize((64,64)), # Resize the images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image pixels to the range [-1, 1]\n",
    "])\n",
    "\n",
    "\n",
    "# Load the high-resolution and low-resolution images\n",
    "hr_dataset = ImageFolder(root=data_path + \"lr\", transform=transform)\n",
    "lr_dataset = ImageFolder(root=data_path + \"lr\", transform=transformLr)\n",
    "#sr_dataset = ImageFolder(root=data_path + \"autoencodertrain\", transform=transform)\n",
    "\n",
    "# Create the data loader for high-resolution and low-resolution images\n",
    "batch_size = 6\n",
    "num_workers = 2  # Set the number of worker processes for data loading\n",
    "hr_data_loader = DataLoader(hr_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "lr_data_loader = DataLoader(lr_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.702306700Z",
     "start_time": "2023-07-16T00:08:00.679302100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.716309300Z",
     "start_time": "2023-07-16T00:08:00.691304800Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.766560Z",
     "start_time": "2023-07-16T00:08:00.709308600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "autoencoder = SRResnet()\n",
    "\n",
    "# Move the models to the device\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Define the loss function (adversarial and content losses)\n",
    "ae_content_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.785564200Z",
     "start_time": "2023-07-16T00:08:00.740317100Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the optimizers for generator and discriminator\n",
    "lr = 0.0001\n",
    "betas = (0.5, 0.9)\n",
    "autoencoder_optimizer = optim.Adam(autoencoder.parameters(), lr = lr, betas = betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x2c2e0713490>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:00.786564600Z",
     "start_time": "2023-07-16T00:08:00.754557200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5000], Step [10/41], AELoss: 0.1007\n",
      "Epoch [1/5000], Step [20/41], AELoss: 0.1057\n",
      "Epoch [1/5000], Step [30/41], AELoss: 0.0932\n",
      "Epoch [1/5000], Step [40/41], AELoss: 0.1144\n",
      "Saved AE model at epoch 1, batch 41\n",
      "Epoch [2/5000], Step [10/41], AELoss: 0.0630\n",
      "Epoch [2/5000], Step [20/41], AELoss: 0.0866\n",
      "Epoch [2/5000], Step [30/41], AELoss: 0.0784\n",
      "Epoch [2/5000], Step [40/41], AELoss: 0.1034\n",
      "Epoch [3/5000], Step [10/41], AELoss: 0.0549\n",
      "Epoch [3/5000], Step [20/41], AELoss: 0.0800\n",
      "Epoch [3/5000], Step [30/41], AELoss: 0.0720\n",
      "Epoch [3/5000], Step [40/41], AELoss: 0.0964\n",
      "Saved AE model at epoch 3, batch 41\n",
      "Epoch [4/5000], Step [10/41], AELoss: 0.0509\n",
      "Epoch [4/5000], Step [20/41], AELoss: 0.0754\n",
      "Epoch [4/5000], Step [30/41], AELoss: 0.0676\n",
      "Epoch [4/5000], Step [40/41], AELoss: 0.0913\n",
      "Epoch [5/5000], Step [10/41], AELoss: 0.0480\n",
      "Epoch [5/5000], Step [20/41], AELoss: 0.0723\n",
      "Epoch [5/5000], Step [30/41], AELoss: 0.0638\n",
      "Epoch [5/5000], Step [40/41], AELoss: 0.0871\n",
      "Saved AE model at epoch 5, batch 41\n",
      "Epoch [6/5000], Step [10/41], AELoss: 0.0456\n",
      "Epoch [6/5000], Step [20/41], AELoss: 0.0705\n",
      "Epoch [6/5000], Step [30/41], AELoss: 0.0609\n",
      "Epoch [6/5000], Step [40/41], AELoss: 0.0834\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[38], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Training loop\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, num_epochs):\n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (hr_images, sr_images) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mzip\u001B[39m(hr_data_loader, lr_data_loader)):\n\u001B[0;32m      4\u001B[0m         \u001B[38;5;66;03m# Move images to the device\u001B[39;00m\n\u001B[0;32m      5\u001B[0m         hr_images \u001B[38;5;241m=\u001B[39m hr_images[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n\u001B[0;32m      6\u001B[0m         sr_images \u001B[38;5;241m=\u001B[39m sr_images[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mfloat()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    630\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    631\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    632\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 633\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    635\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    636\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1325\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m-> 1328\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1329\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   1330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[0;32m   1331\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1294\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1290\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[0;32m   1291\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[0;32m   1292\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1293\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m-> 1294\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_try_get_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1295\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[0;32m   1296\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m   1119\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[0;32m   1120\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[0;32m   1121\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1129\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[0;32m   1130\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[0;32m   1131\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1132\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_data_queue\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[0;32m   1134\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[0;32m   1137\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\multiprocessing\\queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[1;34m(self, block, timeout)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[0;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[1;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[0;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\multiprocessing\\connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[0;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[1;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_poll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\multiprocessing\\connection.py:330\u001B[0m, in \u001B[0;36mPipeConnection._poll\u001B[1;34m(self, timeout)\u001B[0m\n\u001B[0;32m    327\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_got_empty_message \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[0;32m    328\u001B[0m             _winapi\u001B[38;5;241m.\u001B[39mPeekNamedPipe(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 330\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\multiprocessing\\connection.py:879\u001B[0m, in \u001B[0;36mwait\u001B[1;34m(object_list, timeout)\u001B[0m\n\u001B[0;32m    876\u001B[0m                 ready_objects\u001B[38;5;241m.\u001B[39madd(o)\n\u001B[0;32m    877\u001B[0m                 timeout \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 879\u001B[0m     ready_handles \u001B[38;5;241m=\u001B[39m \u001B[43m_exhaustive_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwaithandle_to_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m     \u001B[38;5;66;03m# request that overlapped reads stop\u001B[39;00m\n\u001B[0;32m    882\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m ov \u001B[38;5;129;01min\u001B[39;00m ov_list:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torchinho\\lib\\multiprocessing\\connection.py:811\u001B[0m, in \u001B[0;36m_exhaustive_wait\u001B[1;34m(handles, timeout)\u001B[0m\n\u001B[0;32m    809\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m L:\n\u001B[1;32m--> 811\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43m_winapi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mWaitForMultipleObjects\u001B[49m\u001B[43m(\u001B[49m\u001B[43mL\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    812\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;241m==\u001B[39m WAIT_TIMEOUT:\n\u001B[0;32m    813\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(0, num_epochs):\n",
    "    for i, (hr_images, sr_images) in enumerate(zip(hr_data_loader, lr_data_loader)):\n",
    "        # Move images to the device\n",
    "        hr_images = hr_images[0].to(device).float()\n",
    "        sr_images = sr_images[0].to(device).float()\n",
    "\n",
    "        if i == 40 and epoch == 0:\n",
    "            save_image(hr_images, f\"AE-results/hr_image_epoch{epoch + 1}_batch{i+1}.png\", normalize = True)\n",
    "            save_image(sr_images, f\"AE-results/lr_image_epoch{epoch + 1}_batch{i+1}.png\", normalize = True)\n",
    "\n",
    "        # --------------------\n",
    "        # Train the Autoencoder\n",
    "        # --------------------\n",
    "        ae_sr_images = autoencoder(sr_images)\n",
    "        autoencoder_optimizer.zero_grad()\n",
    "        ae_loss = ae_content_loss(hr_images, ae_sr_images)\n",
    "        ae_loss.backward(retain_graph =True)\n",
    "        autoencoder_optimizer.step()\n",
    "\n",
    "        # Print progress\n",
    "        if(i + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(hr_data_loader)}], \"\n",
    "                f\"AELoss: {ae_loss.item():.4f}\")\n",
    "\n",
    "        if (i + 1) % 41 == 0 and ((epoch % 2) == 0):\n",
    "            torch.save(autoencoder.state_dict(), f\"Models/AE/autoencoder_model_epoch{epoch+1}_batch{i+1}.pt\")\n",
    "            print(f\"Saved AE model at epoch {epoch+1}, batch {i+1}\")\n",
    "\n",
    "            #save_image(sr_images, f\"AE-results/sr_image_epoch{epoch + 1}_batch{i+1}.png\", normalize = True)\n",
    "            save_image(ae_sr_images, f\"AE-results/ae_sr_image_epoch{epoch + 1}_batch{i+1}.png\", normalize = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-16T00:08:48.597337500Z",
     "start_time": "2023-07-16T00:08:00.776562Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
